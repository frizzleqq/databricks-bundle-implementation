# The main job for dbx_example.
resources:
  jobs:
    dbx_yaml_job:
      name: dbx_yaml_job

      trigger:
        # Run this job every day, exactly one day from the last run; see https://docs.databricks.com/api/workspace/jobs/create#trigger
        periodic:
          interval: 1
          unit: DAYS

      tasks:
        - task_key: bronze_taxi
          environment_key: default
          python_wheel_task:
            package_name: dbx_example
            entry_point: dbx-example
            parameters:
              - BronzeTaxiTask
              - --catalog
              - ${var.catalog_name}

        - task_key: bronze_accuweather
          environment_key: default
          python_wheel_task:
            package_name: dbx_example
            entry_point: dbx-example
            parameters:
              - BronzeAccuweatherTask
              - --catalog
              - ${var.catalog_name}

        - task_key: silver_nyctaxi_aggregate
          environment_key: default
          python_wheel_task:
            package_name: dbx_example
            entry_point: dbx-example
            parameters:
              - SilverTaxiAggTask
              - --catalog
              - ${var.catalog_name}
          depends_on:
            - task_key: bronze_taxi
            - task_key: bronze_accuweather
          run_if: ALL_SUCCESS

      # Environment required for Python tasks
      environments:
        - environment_key: default

          # Full documentation of this spec can be found at:
          # https://docs.databricks.com/api/workspace/jobs/create#environments-spec
          spec:
            # If we use Python-based Workflows, we need to specify environment_version instead of client.
            # client: ${var.serverless_environment_version}
            environment_version: ${var.serverless_environment_version}
            dependencies:
              - ../dist/*.whl
